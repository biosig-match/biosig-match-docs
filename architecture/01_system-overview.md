リアルタイム解析の API エンドポイントをユーザー ID ごとに分けたほうが，将来的にスマホアプリとエンドポイントの認証の観点では理想的かも．

スマホアプリからの圧縮データ送信は，JSON でバイナリの圧縮データを囲ってアップロードする．ユーザー ID の付与は必要だが，デバイス ID の付与に関しては，

① 圧縮データを解凍する

② デバイス ID を取得する

③ デバイス ID を付与する

という流れをスマホ側で待つのがボトルネックになるのではないかと思う．ユーザー ID だけの付与ならスマホ側で決め打ちなので高速に実現できるはず．

そもそも圧縮データの中にデバイス ID が入っているほか，各キューの負担を減らすため先述したサーバーの構造から以下のように変化する見込み．

・コレクターは圧縮データを受け取り，プロデューサーとして圧縮データをエクスチェンジに送る．プロセッサーとリアルタイムアナライザーはこのエクスチェンジに対する別々のコンシューマーとなり，それぞれのキューに圧縮データが入る．つまり，リアルタイムアナライザーはプロセッサーを無駄に介さなくなる．

・プロセッサーは，圧縮データを解凍し，デバイス ID を取得すると同時に，IMU や脳波といったデータの種類ごとに分離する．取り出されて分離したダイレクトな生データごとに再度圧縮し，それぞれユーザー ID とデバイス ID を付与してオブジェクトストレージ minio に格納する．minio 内のオブジェクト ID を早い段階で取得できないと困るが，格納に時間がかかってもいいように実際に格納する前に minio 側ですぐにオブジェクト ID を決めてプロセッサーに返してもらうようにするか，キューの待ち時間が不要なより理想的な方法としてはプロセッサー側でオブジェクト ID を決めて付与して minio に送ることを想定している．minio に圧縮データを渡した後の PostgreDB におけるメタデータ管理ではオブジェクト ID だけを使うことができ，理想的．

・リアルタイムアナライザーは，プロセッサーを待たずに 10 秒ごとにキューに溜まった圧縮データを解凍し，デバイス ID の付与およびリアルタイム解析を開始できる．この処理は実験 ID などを必要としないため分離も容易．解析結果をユーザー ID ごとのエンドポイントに置くだけ．最新でない画像は消すようにした方がいいかも（すでにそのようにしているかどうかは確認してない）．

コンシューマー側は必ず最初に圧縮データを解凍する処理を含むため，デバイス ID はその段階で確実に入手できる．スマホアプリ側で付与するのはユーザー ID と，実験中であれば，実験中かどうかを示す 0/1 のフラグか，あるいはスマホ側で決めた実験 ID（ユーザー ID と実験開始時刻のミリ秒を結合した文字列など，サーバー側でも一意の値．BIDS の形式にできるならこの限りではない）を付与するだけで十分．

また，bids_manager は求められた際に静的なデータに対して動作する，オブジェクトストレージと PostgreDB から単一の実験 ID を持つすべてのデータを収集し，時系列順に並び替え・切り出しを行い，適切なファイル名に成型したりして，BIDS で出力する．

実験 ID と実験中かどうかのフラグを圧縮データに付与するのはやめる．

圧縮されたデータがスマホに届くのは BLE 通信の後なので，実際にサンプリングされたタイミングではない．また，BIDS では実験 ID は「複数被験者がそれぞれの時間帯で行った実験，あるいは同じ被験者が複数回行った実験」の全体に付与されるものだったので，1 ユーザーの計測開始から終了までのセッションにつける ID としては，「実験 ID」ではなく「セッション ID」という名前がふさわしい．同じ実験のセッション ID をまとめるのが「実験 ID」の役割だと思う．セッション開始時に，開始するセッションが既にある実験に属す場合は実験 ID を入力させ，新規実験の場合はサーバーに問い合わせてサーバー内で一意の実験 ID を発行してもらう形がいいと思う．したがってサーバー側にはそれ専用のエンドポイントが必要．後述するセッション管理用の処理を動かすサービスか，コレクター上に設けるのがいいと思う．

セッション ID の命名規則はのちの検索に備えてユーザー ID とセッション開始時刻と終了時刻それぞれの UNIX 時間を結合したものにしておくといいと思う．

セッション ID を付与するのは，スマホ側で実験開始から終了までの間だけ取得している画像(10 秒の真ん中，ちょうど 5 秒目に撮影して 1 枚ずつアップロード)，音声(10 秒間ごとアップロード)，そしてセッション終了時にアップロードするイベントリスト(.csv)だけである．これらにはユーザー ID も付与してアップロードする．

圧縮データ側はマイコン側でタイムスタンプを付与していたはず．サーバーではこれらとスマホ側のタイムスタンプを調整してから保存する処理になっているはずで，これは効果があれば今後も残す計画．

この調整済みタイムスタンプを持つ圧縮側のデータ群には，オブジェクトストレージへの格納単位（0.5 秒～ 10 秒分）ごとに，各オブジェクトのデータの開始時刻と終了時刻を UNIX 時間でメタデータあるいはファイル名で持たせておく．

これにより，セッション終了時にセッション開始時刻とセッション終了時刻をセッション ID とともにアップロードしておけば，指定したユーザーの指定したセッションの開始時刻または終了時刻を含む，あるいはセッションの開始時刻と終了時刻の間に含まれる時間帯のデータを持つオブジェクトをオブジェクトストレージから検索することで，セッションに含まれるすべてのデータを集めることができる．あとはそれらのオブジェクトのデータを結合した後に，真にセッション開始時刻と終了時刻の間にあるデータだけを切り出せばよい．この処理は大変である可能性が高いが，オブジェクトストレージ内を検索してセッション ID を付与する処理は BIDS によるエクスポートが要求される前に（セッション終了時にセッション開始時刻・終了時刻を受け取った段階で）実行しておくことができるため，時間がかかることに関しては問題はない．また，切り出しまで行ってから完全なセッションのデータをオブジェクトストレージに再格納することも考えたが，すでに入っている元のデータと重複しながら保存容量を圧迫するため，エクスポートの高速化が求められない限りそこまではしなくてよいと思う．

また，セッション ID だけでなく，そのセッションがキャリブレーションか本実験かを見分けられるフラグを付与してその情報を最低 1 回送るか，よりスマートにはセッション ID の命名規則に含んだ方がいい．どのセッションがどのセッションのキャリブレーションなのか，という 1 対多の紐づけができたらもっと理想的．どちらにせよメタデータとしてすべてのデータに付与する必要はない．
